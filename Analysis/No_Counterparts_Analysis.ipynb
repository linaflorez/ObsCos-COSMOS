{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits as fits\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import match_coordinates_sky\n",
    "from astropy.coordinates import search_around_sky\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import Angle, SkyCoord\n",
    "import matplotlib.cm as cm\n",
    "from scipy.ndimage import gaussian_filter as gf\n",
    "from astropy.nddata import Cutout2D\n",
    "import astropy.visualization as viz\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import ZScaleInterval\n",
    "import astropy.coordinates as coords\n",
    "from astropy.visualization.wcsaxes import WCSAxes\n",
    "import astropy.visualization.wcsaxes.frame as frame\n",
    "from astropy.table import Table\n",
    "import pandas as pd\n",
    "from scipy.stats import kde\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import reproject\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Getting RA and DEC of cross-matched sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"INVISIBLE.csv\")\n",
    "folder_path = \"/Users/linaflorez/Desktop/ObsCos/COSMOS_research/Restart/FITS_FILES/\"\n",
    "\n",
    "hscmap_input = pd.DataFrame()\n",
    "hscmap_input[\"RA\"], hscmap_input[\"dec\"] = df[\"ra\"], df[\"dec\"]\n",
    "hscmap_input.to_csv(\"hscmap_input.csv\")\n",
    "df.RA_x, df.ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Making folders to add respective fits files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "When we get files from hscmap, the respective cutouts' FITS files contain no information about the source in their file names. Because of that, we need to find a way to organize the fits files in the event we want to analyize FITS files with particular properties. The only way I found to address this problem is to create a series of files, named by the RAs of the sources we are concerned with. Thru the path files I hope to discern the FITS files from their original sources. Crude, but a good fix for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "folder_path = \"/Users/linaflorez/Desktop/ObsCos/COSMOS_research/Analysis/FITS_FILES/\"\n",
    "\n",
    "ra = (df[\"ra\"]).astype(str)\n",
    "\n",
    "# for folder in ra:\n",
    "#     os.mkdir(os.path.join(folder_path,folder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Organizing FITS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now I have the go through all of these RA-named files to take out specific bands (i.e. G, R, I, Z, Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "g_fits = []\n",
    "r_fits = []\n",
    "i_fits = []\n",
    "y_fits = []\n",
    "z_fits = []\n",
    "folder_path_name = \"/Users/linaflorez/Desktop/ObsCos/COSMOS_research/Analysis/FITS_FILES\"\n",
    "\n",
    "for subdir, dirs, files in os.walk(folder_path_name):\n",
    "    for file in files:\n",
    "        if file.startswith(\"cutout-HSC-G\"):\n",
    "            g_fits.append([os.path.join(subdir, file).split(os.sep)[-2],os.path.join(subdir, file)])\n",
    "        if file.startswith(\"cutout-HSC-R\"):\n",
    "            r_fits.append([os.path.join(subdir, file)])\n",
    "        if file.startswith(\"cutout-HSC-I\"):\n",
    "            i_fits.append([os.path.join(subdir, file)])\n",
    "        if file.startswith(\"cutout-HSC-Y\"):\n",
    "            z_fits.append([os.path.join(subdir, file)])\n",
    "        if file.startswith(\"cutout-HSC-Z\"):\n",
    "            y_fits.append([os.path.join(subdir, file)])\n",
    "            \n",
    "g_fits = np.array(g_fits)\n",
    "r_fits = np.array(r_fits)\n",
    "i_fits = np.array(i_fits)\n",
    "y_fits = np.array(y_fits)\n",
    "z_fits = np.array(z_fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We had an original csv that contained all of the information for the sources with no counterparts, and here I'm converting it to a dataframe so we can add the FITS file paths to the csv to reference in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "updated_df = pd.read_csv(\"INVISIBLE.csv\", usecols = lambda column : column not in \n",
    "['Unnamed: 0', 'Unnamed: 0.1','GRI/IZY', 'Visible','Invisible', 'Saturated', 'Visible, Near Saturated Object',\\\n",
    " 'Not Visible, Near Saturated Object', 'Visible, but near an object',\\\n",
    " 'Not Visible, but near an object', 'Unclear'])\n",
    "updated_df.to_csv(\"invisible_sources_updated.csv\")\n",
    "updated_df.RA_x.values[0:10], updated_df.ra.values[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Indexing to Update CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The fun part was that when we go thru the folders containing the FITS files and pull out their file names, the arrays were NOT in the same order as the RAs within the dataframe, so here I'm correcting the indexing to the FITS files to be placed in the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "indexing = []\n",
    "for ra_val in updated_df.ra.values:\n",
    "    for index, val in enumerate(g_fits):\n",
    "        if ra_val == float(val[0]):\n",
    "            indexing.append(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After further inspection, more sources to ignore..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_to_reject = [149.99096995989999,150.31280999290001,150.014007568359,150.0368600085,\\\n",
    "150.044163961,149.870119959,150.466509985,150.30997643,150.3327999931,\\\n",
    "150.01580999979998,149.838489959,150.22795999049998,149.924705867,149.71426655,\\\n",
    "149.74107997229999,149.8705499936,149.908649983,150.0629500023,150.1785799884,\\\n",
    "150.490958282,150.190563658,150.606725205]\n",
    "\n",
    "print(\"Number of sources rejected: %i\" % (len(sources_to_reject)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Making the compiled csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "x = np.concatenate((g_fits[:,1].reshape(106,1),r_fits,i_fits,z_fits,y_fits), axis = 1)\n",
    "df2 = pd.DataFrame(data = x[indexing], columns=['gfits', 'rfits', 'ifits', 'zfits', 'yfits'])\n",
    "result = pd.concat([updated_df, df2], axis=1, sort=False)\n",
    "result = result[~result['ra'].isin(sources_to_reject)]\n",
    "result.to_csv(\"everything_you_need.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "checking_chandra = pd.DataFrame()\n",
    "checking_chandra[\"ra\"] = result.ra\n",
    "checking_chandra[\"dec\"] = result.dec\n",
    "\n",
    "checking_chandra.to_csv(\"checking_chandra.csv\", index = False)\n",
    "checking_chandra.ra.values[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Patch of sky where sources are located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-white\")\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.title(\"Sources: %i \\n (w/o counterpart)\" % (result.shape[0]), weight = \"bold\", size = 25)\n",
    "plt.scatter(result.ra, result.dec, color = \"c\")\n",
    "plt.xlabel(\"RA\", weight = \"bold\", size = 20)\n",
    "plt.ylabel(\"Dec\", weight = \"bold\", size = 20)\n",
    "plt.tick_params(\"both\", labelsize = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making cutouts 3\" x 3\" function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to make further cutouts within python (in this case 3\" x 3\"), because when we do the cutouts from hscMap, the center of the cutout is NOT necessarily the location of the source (as much as I tried!). ALSO, the cutout sizes are necessarily the same sizes, so stacking without doing one more trim would not make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Note: 🤔\n",
    "FITS Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#just downloading image\n",
    "# hdulist_ = fits.open(\"/Users/linaflorez/Downloads/cutout-HSC-Y-9813-pdr2_dud-200228-070200.fits\")\n",
    "# hdulist_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#downloading image and mask\n",
    "# hdulist_ = fits.open(\"/Users/linaflorez/Downloads/cutout-HSC-Y-9813-pdr2_dud-200228-070412.fits\")\n",
    "# hdulist_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#downloading image, mask, and variance\n",
    "# hdulist_ = fits.open(\"/Users/linaflorez/Downloads/cutout-HSC-Y-9813-pdr2_dud-200228-070637.fits\")\n",
    "# hdulist_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def cutout_func(band):  \n",
    "    #contains all of the relevant fits files\n",
    "    result = pd.read_csv(\"everything_you_need.csv\")  \n",
    "    \n",
    "    #initializing blank arrays\n",
    "    num = np.zeros((18,18))\n",
    "    denom = np.zeros((18,18))\n",
    "    \n",
    "    flux_mag0 = []\n",
    "    for i in range(len(result)):\n",
    "        #Getting RA and Dec of source for cutout\n",
    "        respective_band = result[band].iloc[i]\n",
    "        RA = result[\"ra\"].iloc[i]\n",
    "        DEC = result[\"dec\"].iloc[i]\n",
    "        hdulist = fits.open(respective_band)\n",
    "        flux_mag0.append(hdulist[0].header[\"FLUXMAG0\"])\n",
    "        \n",
    "        \n",
    "        # Courtesy of hscMap \n",
    "        image = hdulist[1].data\n",
    "        mask = hdulist[2].data\n",
    "        variance = hdulist[3].data #for inverse variance\n",
    "\n",
    "        # Prepping for cutout\n",
    "        wcs = WCS(hdulist[1].header)\n",
    "        coords = SkyCoord(ra=RA*u.degree, dec=DEC*u.degree)\n",
    "        cut_center = SkyCoord(coords)\n",
    "        size = 3 #arcsecs\n",
    "        cutout_size = np.array([size, size]) * u.arcsec\n",
    "\n",
    "        # Doing a cutout on the image array\n",
    "        cutout = Cutout2D(image, cut_center, cutout_size, wcs)\n",
    "\n",
    "        # Doing a cutout on the variance array\n",
    "        variance = Cutout2D(variance, cut_center, cutout_size, wcs=wcs).data\n",
    "\n",
    "\n",
    "        # Σ_i of (flux_ij/sigma_ij^2)\n",
    "        num += cutout.data/variance\n",
    "        \n",
    "        # Σ_i of (1/sigma_ij^2)\n",
    "        denom += 1/variance\n",
    "        \n",
    "\n",
    "    #stacked cutout array\n",
    "    cutouts = num/denom \n",
    "    \n",
    "    #Determining the magnitude of the \"source at the center\"\n",
    "    smaller_section = cutouts[6:12,6:12]\n",
    "    magnitude = -2.5 * np.log10(np.sum(smaller_section)/flux_mag0[0])\n",
    "    flux = np.sum(smaller_section) \n",
    "    \n",
    "    #Determining error \n",
    "    error = np.sqrt(1/denom)\n",
    "    flux_err = np.sqrt(np.sum(error[6:12,6:12]))\n",
    "\n",
    "    # Plotting stacked image!\n",
    "    plt.style.use(\"dark_background\")\n",
    "    fig,(ax1) = plt.subplots(1,1, figsize = (15,10))\n",
    "    title = (\"Stacking %i %s sources w/o counterparts \\n Magnitude of central source/pixels: %.3f\" % (result.shape[0], band, magnitude))\n",
    "    plt.title(title, weight = \"bold\", size = 20)\n",
    "    plot = plt.imshow(cutouts, cmap = \"plasma\", extent=[-size/2 ,size/2,-size/2 ,size/2], aspect='auto')\n",
    "    plt.contour(cutouts, 5, extent=[-size/2 ,size/2,-size/2 ,size/2],cmap='Greys')\n",
    "    plt.xlabel(\"Arcsecs\", weight = \"bold\", size = 20)\n",
    "    plt.ylabel(\"Arcsecs\", weight = \"bold\", size = 20)\n",
    "    plt.tick_params(\"both\", labelsize = 20)\n",
    "    cbar = fig.colorbar(plot)\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    plt.savefig(\"stacked_%s.pdf\" % band)\n",
    "    \n",
    "    return \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performing cutouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cutout_func(\"gfits\"),cutout_func(\"rfits\"),cutout_func(\"ifits\"),cutout_func(\"zfits\"),cutout_func(\"yfits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_chandra.ra.iloc[0:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make sure that the stacking code is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COSMOS_info = pd.read_csv(\"/Users/linaflorez/Desktop/ObsCos/COSMOS_research/venv/Color_COSMOS_DD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The contents of the COSMOS file: \\n\",COSMOS_info.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.read_csv(\"/Users/linaflorez/Desktop/ObsCos/COSMOS_research/venv/VISIBLE.csv\")\n",
    "match_df = match_df[match_df.Unclear != \"Y\"][match_df.Visible == \"Y\"]\n",
    "match_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df[\"dec\"].isin(COSMOS_info[\"dec\"]).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://hsc-release.mtk.nao.ac.jp/das_cutout/pdr2/manual.html#list-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respective_band = result[\"gfits\"].iloc[0]\n",
    "RA = result[\"ra\"].iloc[0]\n",
    "DEC = result[\"dec\"].iloc[0]\n",
    "hdulist = fits.open(respective_band)\n",
    "print(\"FITS INFO:\",hdulist.info(), hdulist[0].header, hdulist[1].data)\n",
    "flux_mag0 = hdulist[0].header[\"FLUXMAG0\"]\n",
    "\n",
    "\n",
    "#(1)Do this for sources with counterparts\n",
    "#(2)Check to make sure that the magnitudes in the center pixels are what we want them to be: ~26mag\n",
    "magnitudes = -2.5 * np.log10(hdulist[1].data/flux_mag0) # flux units to magnitudes, flux units on colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='/Users/linaflorez/Desktop/ObsCos/COSMOS_research/Readings/Screen Shot 2020-02-26 at 1.46.21 AM.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting visible source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = pd.read_csv(\"no_match_stats.csv\")\n",
    "visible_sources_no_match = match_df[match_df.Unclear != \"Y\"][match_df.Visible == \"Y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing flux of visible and invisible sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-white')\n",
    "fig, ((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize = (20,25))\n",
    "\n",
    "ax1.set_title(\"Flux_F: %i Invisible sources\" % (np.shape(result)[0]), weight = \"bold\", size = 27)\n",
    "bins_F=np.linspace(1e-15,1e-14,20) #BIN MADE HERE!!!\n",
    "ax1.hist(result.flux_F, bins = bins_F, ec='black')[2]\n",
    "ax1.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax1.tick_params(\"both\", labelsize = 25)\n",
    "\n",
    "ax2.set_title(\"Flux_F: %i Visible sources\" % (np.shape(visible_sources_no_match)[0]), weight = \"bold\", size = 27)\n",
    "ax2.hist(visible_sources_no_match[\"flux_F\"], bins = bins_F, ec='black')[2]\n",
    "ax2.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax2.tick_params(\"both\", labelsize = 25)\n",
    "\n",
    "#####################\n",
    "\n",
    "ax3.set_title(\"Flux_S: %i Invisible sources\" % (np.shape(result)[0]), weight = \"bold\", size = 27)\n",
    "ax3.hist(result.flux_S, bins= bins_F, ec='black')[2]\n",
    "ax3.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax3.tick_params(\"both\", labelsize = 25)\n",
    "\n",
    "ax4.set_title(\"Flux_S: %i Visible sources\" % (np.shape(visible_sources_no_match)[0]), weight = \"bold\", size = 27)\n",
    "ax4.hist(visible_sources_no_match[\"flux_S\"], bins=bins_F, ec='black')[2]\n",
    "ax4.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax4.tick_params(\"both\", labelsize = 25)\n",
    "\n",
    "#####################\n",
    "\n",
    "ax5.set_title(\"Flux_H: %i Invisible sources\" % (np.shape(result)[0]), weight = \"bold\", size = 27)\n",
    "ax5.hist(result.flux_H, bins = bins_F, ec='black')[2]\n",
    "ax5.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax5.tick_params(\"both\", labelsize = 25)\n",
    "\n",
    "ax6.set_title(\"Flux_H: %i Visible sources\" % (np.shape(visible_sources_no_match)[0]), weight = \"bold\", size = 27)\n",
    "ax6.hist(visible_sources_no_match[\"flux_H\"], bins = bins_F, ec='black')[2]\n",
    "ax6.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax6.tick_params(\"both\", labelsize = 25)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\Sigma}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same plots but with qq plots added on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "plt.style.use('seaborn-white')\n",
    "fig, ((ax1,ax2), (ax3,ax4),(ax5,ax6)) = plt.subplots(3,2,figsize = (20,20))\n",
    "\n",
    "ax1.set_title(\"Flux_F: %i \\n Invisible sources\" % (np.shape(result)[0]), weight = \"bold\", size = 27)\n",
    "bins_F=np.linspace(1e-15,1e-14,20) #BIN MADE HERE!!!\n",
    "ax1.hist(result.flux_F, bins = bins_F, ec='black')[2]\n",
    "ax1.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax1.tick_params(\"both\", labelsize = 25)\n",
    "sm.qqplot(np.asarray(result.flux_F), line = \"q\",ax = ax2)\n",
    "\n",
    "\n",
    "ax3.set_title(\"Flux_S: %i Invisible sources\" % (np.shape(result)[0]), weight = \"bold\", size = 27)\n",
    "ax3.hist(result.flux_S, bins= bins_F, ec='black')[2]\n",
    "ax3.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax3.tick_params(\"both\", labelsize = 25)\n",
    "sm.qqplot(np.asarray(result.flux_F), line = \"q\",ax = ax4)\n",
    "\n",
    "\n",
    "ax5.set_title(\"Flux_H: %i Invisible sources\" % (np.shape(result)[0]), weight = \"bold\", size = 27)\n",
    "ax5.hist(result.flux_H, bins= bins_F, ec='black')[2]\n",
    "ax5.set_xlabel(\"(0.5–10 keV Flux ${[erg cm^{−2} s^{−1}]}$)\", weight = \"bold\", size = 25)\n",
    "ax5.tick_params(\"both\", labelsize = 25)\n",
    "sm.qqplot(np.asarray(result.flux_H), line = \"q\",ax = ax6)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
